import os
import json
import faiss
import numpy as np
import requests
from typing import List
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from flask import Flask, request, render_template, jsonify

OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "llama3.2"
FOLDER_PATH = "data"
INDEX_PATH = "faiss.index"
TEXTS_PATH = "texts.json"

app = Flask(__name__)
embedder = SentenceTransformer("intfloat/multilingual-e5-base")

def load_laws(filepath: str) -> List[str]:
    with open(filepath, "r", encoding="utf-8") as f:
        data = json.load(f)
    texts = [f"{law['law_name']} ‡∏°‡∏≤‡∏ï‡∏£‡∏≤ {law['section_num']}:\n{law['section_content']}" for law in data]
    return texts

def load_laws_from_folder(folder_path: str) -> List[str]:
    all_texts = []
    print(f"üìö ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {folder_path}")
    for filename in os.listdir(folder_path):
        if filename.endswith('.json'):
            file_path = os.path.join(folder_path, filename)
            try:
                texts = load_laws(file_path)
                all_texts.extend(texts)
                print(f"‚úì ‡πÇ‡∏´‡∏•‡∏î {filename} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ({len(texts)} ‡∏°‡∏≤‡∏ï‡∏£‡∏≤)")
            except Exception as e:
                print(f"‚úó ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î {filename}: {str(e)}")
    return all_texts

def embed_chunks(texts: List[str], batch_size: int = 16) -> np.ndarray:
    print("üîç ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings...")
    embeddings = embedder.encode(texts, batch_size=batch_size, show_progress_bar=True,
                                 convert_to_numpy=True, normalize_embeddings=True)
    return embeddings

def build_faiss_index(embeddings: np.ndarray) -> faiss.IndexFlatIP:
    print("üì¶ ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS Index...")
    index = faiss.IndexFlatIP(embeddings.shape[1])
    index.add(embeddings)
    return index

def search_similar_contexts(query: str, texts: List[str], index: faiss.IndexFlatIP, top_k: int = 5) -> List[str]:
    print("üß† ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    query_embedding = embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True)
    scores, indices = index.search(query_embedding, top_k)

    threshold = 0.4
    filtered_results = [(texts[i], scores[0][idx]) for idx, i in enumerate(indices[0])
                        if scores[0][idx] > threshold]
    filtered_results.sort(key=lambda x: x[1], reverse=True)
    return [text for text, _ in filtered_results]

def generate_answer_ollama(context: str, query: str, max_tokens: int = 512) -> str:
    print("üßæ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ú‡πà‡∏≤‡∏ô Ollama...")
    if context.strip():
        prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÇ‡∏î‡∏¢‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏î‡πâ‡∏ß‡∏¢

‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:
{context}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query}

‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢"""
    else:
        prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query}

‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"""

    response = requests.post(OLLAMA_URL, json={
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "stream": False,
        "options": {
            "num_predict": max_tokens
        }
    })

    if response.status_code == 200:
        return response.json()["response"].strip()
    else:
        return f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Ollama: {response.status_code}"

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/query', methods=['POST'])
def query():
    question = request.json['question']
    top_contexts = search_similar_contexts(question, texts, index)
    context = "\n\n".join(top_contexts)
    answer = generate_answer_ollama(context, question)
    return jsonify({
        'context': context,
        'answer': answer
    })

if __name__ == "__main__":
    # ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡πÅ‡∏Ñ‡∏ä‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    if os.path.exists(INDEX_PATH) and os.path.exists(TEXTS_PATH):
        print("üìÇ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏Ñ‡∏ä...")
        index = faiss.read_index(INDEX_PATH)
        with open(TEXTS_PATH, "r", encoding="utf-8") as f:
            texts = json.load(f)
    else:
        texts = load_laws_from_folder(FOLDER_PATH)
        if not texts:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå")
            exit(1)

        print(f"\nüìù ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(texts)} ‡∏°‡∏≤‡∏ï‡∏£‡∏≤")
        embeddings = embed_chunks(texts)
        index = build_faiss_index(embeddings)

        # ‡πÅ‡∏Ñ‡∏ä‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        faiss.write_index(index, INDEX_PATH)
        with open(TEXTS_PATH, "w", encoding="utf-8") as f:
            json.dump(texts, f, ensure_ascii=False)

    print("\nüéØ ‡∏£‡∏∞‡∏ö‡∏ö RAG (Ollama) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!\n")
    app.run(host='0.0.0.0', port=5000, debug=True)
